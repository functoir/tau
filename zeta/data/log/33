An empirical analysis of compute-optimal large language model training

https://www.deepmind.com/publications/an-empirical-analysis-of-compute-optimal-large-language-model-training

   68 a
   13 be
    7 billion
    1 both
    3 budget
    1 but
    3 by
    2 computational
    8 compute
    1 consequence
    1 continue
    1 corpus
    4 cost
    1 count
    3 current
    6 data
    2 despite
    1 determined
    1 doubling
    1 downstream
    1 efficient
    1 enough
    1 established
    2 estimate
    1 evaluation
    1 even
    2 every
    1 far
    1 faster
    1 few
    5 find
    1 fixed
    2 focus
   10 for
    1 from
    1 generation
    2 given
    4 has
    1 have
    1 having
    2 hypothesis
    1 impressive
    1 improvement
    1 improving
    1 increased
    4 increasing
    1 inference
    2 investigate
    7 is
    3 it
    2 keeping
   10 language
    9 large
    1 last
    1 leading
    1 led
    1 less
    1 line
    1 main
    1 making
    1 many
    1 may
    1 measured
    1 memory
    1 million
   15 model
    5 more
    1 natural
    1 nearly
    2 not
    5 number
   22 of
   14 on
    4 optimal
    1 other
    3 our
    1 outperform
    2 over
    3 parameter
    1 paramount
    3 performance
    1 performant
    3 possible
    2 predict
    1 processing
    1 provide
    1 querying
    1 question
    3 range
    1 ranging
    1 reading
    2 recent
    1 reduced
    1 release
    1 research
    1 same
    1 scaled
    2 scaling
    1 setup
    2 should
    2 significantly
    1 simple
   10 size
    1 smaller
    2 substantial
    1 such
    1 tasks
    2 test
    9 that
   36 the
    5 this
    1 through
    1 time
   14 to
    7 trained
   18 training
    1 transformer
    2 trillion
    1 two
    1 under
    1 uniformly
    1 used
    2 using
    2 various
    1 wasting
    7 we
    1 while
    1 whilst
    1 wide
    6 with
    2 would

